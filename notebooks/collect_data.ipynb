{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<hr>\n",
    "<h1>Multiplex Dependency Stock Network - Collect Data</h1>\n",
    "<hr>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import quandl \n",
    "quandl.ApiConfig.api_key = 'dYKUm41mFRJiwbdqSMSY' #api key for quandl, register on quandl to get it\n",
    "import math as mt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import ticker o S&P500 components from a csv file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tickers: 505\n"
     ]
    }
   ],
   "source": [
    "companies = []\n",
    "\n",
    "fh = open('../data/input/S&P500List.csv','r')\n",
    "for line in fh: \n",
    "    s = line.strip().split(',') \n",
    "    companies.append(s[0])\n",
    "fh.close()\n",
    "print('Number of Tickers:', len(companies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download data from Quandl API (https://www.quandl.com/) and we record in a dictionary only close prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "for i in companies: \n",
    "    try: \n",
    "        raw_data = quandl.get_table('WIKI/PRICES', \n",
    "                                    qopts = { 'columns': ['ticker', 'date', 'close', 'adj_close'] }, \n",
    "                                    date = { 'gte': '2017-01-01', 'lte': '2017-12-31' },\n",
    "                                    ticker = i)\n",
    "        data[i] = raw_data['close']\n",
    "    except Exception: \n",
    "        print('not found', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform now some controls on data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if some company has not been found we delete it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = []\n",
    "for k in data.keys(): \n",
    "    companies.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we check there are not empty dataframe (and we upload the list of companies): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in companies: \n",
    "    if data[c].empty: \n",
    "        del data[c]\n",
    "companies = []\n",
    "for k in data.keys(): \n",
    "    companies.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we control that all dataframes have the same length (and again we upload the list of companies):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in companies: \n",
    "    if data[c].size != 250: #trading days\n",
    "        del data[c]\n",
    "\n",
    "companies = []\n",
    "for k in data.keys(): \n",
    "    companies.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Return Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate now log return prices before computing correlations (returns follow log normal distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 250\n",
    "\n",
    "datalog = dict() \n",
    "for c in companies: \n",
    "    log = []\n",
    "    for i in range(1,size-1): \n",
    "        log.append(mt.log(data[c].get(i)/data[c].get(i-1)))\n",
    "    logseries = pandas.Series(log)\n",
    "    datalog[c] = logseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrices - Pearson, Kendall, Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosscorr(datax, datay, lag=0, method = 'pearson'):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    return datax.corr(datay.shift(lag), method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate three matrices of correlation using Pearson, Kendall and Spearman methods: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without time lag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(companies)\n",
    "corr_matrix_pearson = np.zeros((n, n))\n",
    "corr_matrix_kendall = np.zeros((n, n))\n",
    "corr_matrix_spearman = np.zeros((n, n))\n",
    "companies_id = dict()\n",
    "\n",
    "for i in range(0, n):\n",
    "    companies_id[companies[i]] = i\n",
    "    for j in range(0, n):\n",
    "        if i<j:\n",
    "            corr_matrix_pearson[i][j] = datalog[companies[i]].corr(datalog[companies[j]],method='pearson')\n",
    "            corr_matrix_kendall[i][j] = datalog[companies[i]].corr(datalog[companies[j]],method='kendall')\n",
    "            corr_matrix_spearman[i][j] = datalog[companies[i]].corr(datalog[companies[j]],method='spearman')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export correlation matrices and tickers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export corr matrix\n",
    "np.savetxt(\"../data/corr_matrix/corr_matrix_pearson.csv\",corr_matrix_pearson, delimiter=\",\")\n",
    "np.savetxt(\"../data/corr_matrix/corr_matrix_kendall.csv\",corr_matrix_kendall, delimiter=\",\")\n",
    "np.savetxt(\"../data/corr_matrix/corr_matrix_spearman.csv\",corr_matrix_spearman, delimiter=\",\")\n",
    "\n",
    "#export ticker e id number\n",
    "import csv\n",
    "with open('../data/input/components.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in companies_id.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
